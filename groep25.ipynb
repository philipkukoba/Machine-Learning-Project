{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Machine Learning: Group 25\n",
    "### Peter Bonnarens, Lennert Franssens & Philip Kukoba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 1 : Tabular Data\n",
    "\n",
    "### Possible tasks:\n",
    "* Thorough exploratory data analysis, e.g.:\n",
    "    * Are there substantial price differences between neighbourhoods ?\n",
    "    * Are there hosts with more than one listing ? How does this impact the price ?\n",
    "    * What is the correlation between the review score and the price ?\n",
    "    * ...\n",
    "\n",
    "    Not enough to just show a plot! Clearly describe WHAT question you investigated, WHY you think this is a relevant question\n",
    "    and WHAT you deduce/conclude from the results of your data analysis\n",
    "\n",
    "* Are there outliers ?\n",
    "* A new Airbnb owner needs to pick an appropriate price:\n",
    "    * Train a model to predict the price based on a selection of features\n",
    "    * Find the most similar listings\n",
    "    \n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of work (who did what)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "|                   \t| EDA step 1 \t| EDA step 2A \t| EDA step 2B \t| EDA step 2C \t| EDA step 2D \t| EDA step 3A \t| EDA step 3B \t|\n",
    "|:-----------------:\t|:----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|\n",
    "|  Peter Bonnarens  \t|      X     \t|             \t|      X      \t|             \t|             \t|             \t|             \t|\n",
    "| Lennert Franssens \t|      X     \t|      X      \t|      X      \t|             \t|      X      \t|      X       \t|             \t|\n",
    "|   Philip Kukoba   \t|      X     \t|             \t|             \t|      X      \t|             \t|             \t|             \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "## Linear Regression Model (LR)\n",
    "|                   \t| LR step 1 \t| LR step 2 \t| LR step 3 \t| LR step 4 \t|\n",
    "|:-----------------:\t|:---------:\t|:---------:\t|:---------:\t|:---------:\t|\n",
    "|  Peter Bonnarens  \t|     X     \t|           \t|           \t|     X     \t|\n",
    "| Lennert Franssens \t|           \t|           \t|           \t|           \t|\n",
    "|   Philip Kukoba   \t|           \t|           \t|           \t|           \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "## K Nearest Neighbors Model (KNN)\n",
    "|                   \t| KNN step 1 \t| KNN step 2 \t| KNN step 3 \t| KNN step 4 \t|\n",
    "|:-----------------:\t|:----------:\t|:----------:\t|:----------:\t|:----------:\t|\n",
    "|  Peter Bonnarens  \t|            \t|            \t|            \t|            \t|\n",
    "| Lennert Franssens \t|            \t|            \t|            \t|            \t|\n",
    "|   Philip Kukoba   \t|            \t|            \t|            \t|            \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: imports & loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 20,16\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# loading the dataset into pandas dataframe\n",
    "listings = pd.read_csv(\"data/listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A : Shift rows\n",
    "We noticed that some rows in the dataset contained data that was shifted 1 column to the right starting from the 'host_id' column. Instead of removing these rows from the dataset, we decided to shift these rows 1 column back to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find lines to shift and add them to a mask - we've found that some lines are shifted 1 to the right beginning on the host_id column (that now contains garbage data)\n",
    "shifted_lines = listings[pd.to_numeric(listings[\"host_verifications\"], errors='coerce').notnull()].id\n",
    "mask = listings['id'].isin(shifted_lines)\n",
    "\n",
    "# shift lines 1 to the left\n",
    "listings.loc[mask, 'host_id':'reviews_per_month'] = listings.loc[mask, 'host_id':'reviews_per_month'].shift(-1, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERK OP: er zijn een paar rijen verschoven (bepaalde kolom die weg is ofzo): shift deze rijen!!!\n",
    "\n",
    "1. host_response_time en host_response_rate: regex om tijdsinterval te kennen, slechte waarden van host_response_time vervangen door juiste waarde in host_response_rate (zie print(listings[ (~listings[\"host_response_rate\"].isnull()) & (~listings[\"host_response_rate\"].str.match('.*%', na=False)) ]) ) en percentage teken bij host_response_rate wegdoen - is omgezet naar een rating (gemakkelijker)\n",
    "2. host acceptance rate: % wegdoen en omzetten naar float. - % is weggedaan, nog omzetten naar float.. (kan nan niet omzetten naar float)\n",
    "3. host total listings count: omzetten naar float\n",
    "4. host verifications: omzetten naar lengte van de array om te kijken op hoeveel manieren een host kan geverifieerd worden (meer trustworthy?)\n",
    "5. host has profile pic: omzetten naar 0 of 1 (misschien meer geboekt als wel profile pic?)\n",
    "6. host identity verified: omzetten naar 0 of 1 (misschien meer geboekt als verified?)\n",
    "8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B : Feature subset selection\n",
    "Before we start cleaning up the data, we first extract the features we think will be useful to explore during this sprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns\n",
    "listings = listings[[\"id\", \"name\", \"host_id\", \"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_total_listings_count\", \"host_verifications\", \"host_has_profile_pic\",\"host_identity_verified\", \"neighbourhood_cleansed\", \"room_type\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"price\", \"minimum_nights\", \"maximum_nights\", \"minimum_minimum_nights\", \"maximum_minimum_nights\", \"minimum_maximum_nights\", \"maximum_maximum_nights\", \"minimum_nights_avg_ntm\", \"maximum_nights_avg_ntm\", \"number_of_reviews\", \"number_of_reviews_ltm\", \"last_review\", \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\", \"instant_bookable\", \"calculated_host_listings_count\", \"calculated_host_listings_count_entire_homes\", \"calculated_host_listings_count_private_rooms\", \"calculated_host_listings_count_shared_rooms\", \"reviews_per_month\"]]\n",
    "# listings.head()\n",
    "print(listings[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2C : Host response time/rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# 0 = best resposne time, 1,2... worse\n",
    "# listings[\"host_response_time\"].unique()\n",
    "\n",
    "listings[\"host_response_time_rating\"] = [0 if x == 'within an hour' \n",
    "                                         else 1 if x == 'within a few hours' \n",
    "                                         else 2 if x == 'within a day' \n",
    "                                         else 3 if x == 'a few days or more' \n",
    "                                         else None \n",
    "                                         for x in listings[\"host_response_time\"]]\n",
    "listings = listings.drop(columns=[\"host_response_time\"])\n",
    "\n",
    "#host_response_rate strip trailing % char\n",
    "\n",
    "listings[\"host_response_rate\"] = [None if x == None else str(x).rstrip('%') for x in listings[\"host_response_rate\"]]\n",
    "listings[\"host_response_rate\"].unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D: Convert currency to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['price'] = listings['price'].replace('[\\$,)]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A : Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = listings.corr().round(2)\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Train - Test - Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: insert chosen features into X\n",
    "X = pd.concat((), axis=1)\n",
    "Y = listings[\"price\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# formule: x-xmin/xmax-xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "y_test_predict = lin_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Measure the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# model evaluation for training set\n",
    "n_train = len(X_train)  # sample size\n",
    "p_train = len(X_train.columns)  # number of independent variables\n",
    "R2_train = r2_score(Y_train, y_train_predict)\n",
    "RMSE_train = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "# use the adjusted R² score to counter accidental increase of score with number of input features.\n",
    "adj_R2_train = 1 - ((1-R2_train) * (n_train-1)/(n_train-p_train-1))   #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "\n",
    "print(\"Model train performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(RMSE_train))\n",
    "print('R2 score is {}'.format(R2_train))\n",
    "print('adjusted R2 score is {}'.format(adj_R2_train))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "n_test = len(X_test)\n",
    "p_test = len(X_test.columns)\n",
    "R2_test = r2_score(Y_test, y_test_predict)\n",
    "RMSE_test = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "adj_R2_test = 1 - ((1-R2_test) * (n_test-1)/(n_test-p_test-1))   #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "\n",
    "print(\"Model test performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(RMSE_test))\n",
    "print('R2 score is {}'.format(R2_test))\n",
    "print('adjusted R2 score is {}'.format(adj_R2_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Model parameters\")\n",
    "print(\"--------------------------------------\")\n",
    "print(lin_model.coef_)\n",
    "print(lin_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Train - Test - Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "dataset = listings\n",
    "\n",
    "#dataset.head()\n",
    "#dataset.describe()\n",
    "print(dataset.price.unique())\n",
    "sns.distplot(dataset.price, bins=50)\n",
    "plt.xlabel(\"Price\")\n",
    "plt.xticks(np.arange(min(dataset.price.to_numpy()), max(dataset.price.to_numpy()), 50.0))\n",
    "plt.show()\n",
    "\n",
    "# TODO\n",
    "sns.pairplot(dataset, hue=\"price\", vars=[\"price\", \"...\", \"...\", \"...\"])\n",
    "\n",
    "sns.catplot(x=\"ca\", y=\"age\", kind=\"swarm\", data=dataset, hue=\"target\")\n",
    "sns.catplot(x=\"thal\", y=\"chol\", kind=\"swarm\", data=dataset, hue=\"target\")\n",
    "\n",
    "\n",
    "# Replace categorical features with one-hot encodings\n",
    "a = pd.get_dummies(dataset['cp'], prefix = \"cp\")\n",
    "b = pd.get_dummies(dataset['thal'], prefix = \"thal\")\n",
    "c = pd.get_dummies(dataset['slope'], prefix = \"slope\")\n",
    "\n",
    "frames = [dataset, a, b, c]\n",
    "dataset = pd.concat(frames, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = [\"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "dataset[columns] = (dataset[columns] - np.min(dataset[columns])) / (np.max(dataset[columns]) - np.min(dataset[columns])).values\n",
    "dataset.describe()\n",
    "\n",
    "# Split data in a training and test set\n",
    "y = dataset.target.values\n",
    "x = dataset.drop(['target'], axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm\n",
    "class MyKNeighborsClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    def fit(self, x, y):\n",
    "        self.tree = KDTree(x)\n",
    "        self.y = y\n",
    "    def predict(self, x):\n",
    "        _, ind = self.tree.query(x, k=self.k)\n",
    "        return self.y[ind].mean(axis=1)\n",
    "\n",
    "\n",
    "knn = MyKNeighborsClassifier(10)\n",
    "knn.fit(x_train, y_train)\n",
    "predictions = knn.predict(x_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Measure the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (predictions == y_test).mean()\n",
    "print(accuracy)\n",
    "\n",
    "TP = (predictions[y_test == 1] == 1).sum()\n",
    "print(TP)\n",
    "\n",
    "TN = (predictions[y_test == 0] == 0).sum()\n",
    "print(TN)\n",
    "\n",
    "FP = (predictions[y_test == 1] == 0).sum()\n",
    "print(FP)\n",
    "\n",
    "FN = (predictions[y_test == 0] == 1).sum()\n",
    "print(FN)\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "print(accuracy)\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "print(precision)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "print(recall)\n",
    "\n",
    "F1 = 2 *  (precision*recall)/(precision+recall)\n",
    "print(F1)\n",
    "\n",
    "accuracies = []\n",
    "for k in range(1, 50):\n",
    "    knn = MyKNeighborsClassifier(k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    predictions = knn.predict(x_test)  > 0.5\n",
    "    accuracies.append((predictions == y_test).mean())\n",
    "plt.plot(accuracies)\n",
    "\n",
    "\n",
    "knn = MyKNeighborsClassifier(5)\n",
    "knn.fit(x_train, y_train)\n",
    "predictions = knn.predict(x_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "\n",
    "for x, y, txt in zip(fpr, tpr, thresholds):\n",
    "    plt.annotate(np.round(txt,2), (x, y-0.04))\n",
    "    \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64c1ee026d8bf8fe0f80fca881c6aaba787117ac29ac9f2de19bb4b209b90df9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
