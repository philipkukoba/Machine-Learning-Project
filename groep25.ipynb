{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Machine Learning: Group 25\n",
    "### Peter Bonnarens, Lennert Franssens & Philip Kukoba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 1 : Tabular Data\n",
    "\n",
    "### Possible tasks:\n",
    "* Thorough exploratory data analysis, e.g.:\n",
    "    * Are there substantial price differences between neighbourhoods ?\n",
    "    * Are there hosts with more than one listing ? How does this impact the price ?\n",
    "    * What is the correlation between the review score and the price ?\n",
    "    * ...\n",
    "\n",
    "    Not enough to just show a plot! Clearly describe WHAT question you investigated, WHY you think this is a relevant question\n",
    "    and WHAT you deduce/conclude from the results of your data analysis\n",
    "\n",
    "* Are there outliers ?\n",
    "* A new Airbnb owner needs to pick an appropriate price:\n",
    "    * Train a model to predict the price based on a selection of features\n",
    "    * Find the most similar listings\n",
    "    \n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of work (who did what)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "|                   \t| EDA step 1 \t| EDA step 2A \t| EDA step 2B \t| EDA step 2C \t| EDA step 2D \t| EDA step 3A \t| EDA step 3B \t|\n",
    "|:-----------------:\t|:----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|:-----------:\t|\n",
    "|  Peter Bonnarens  \t|      X     \t|             \t|      X      \t|             \t|             \t|             \t|             \t|\n",
    "| Lennert Franssens \t|      X     \t|      X      \t|      X      \t|             \t|      X      \t|      X       \t|             \t|\n",
    "|   Philip Kukoba   \t|      X     \t|             \t|             \t|      X      \t|             \t|             \t|             \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "## Linear Regression Model (LR)\n",
    "|                   \t| LR step 1 \t| LR step 2 \t| LR step 3 \t| LR step 4 \t|\n",
    "|:-----------------:\t|:---------:\t|:---------:\t|:---------:\t|:---------:\t|\n",
    "|  Peter Bonnarens  \t|     X     \t|           \t|           \t|     X     \t|\n",
    "| Lennert Franssens \t|           \t|           \t|           \t|           \t|\n",
    "|   Philip Kukoba   \t|           \t|           \t|           \t|           \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "## K Nearest Neighbors Model (KNN)\n",
    "|                   \t| KNN step 1 \t| KNN step 2 \t| KNN step 3 \t| KNN step 4 \t|\n",
    "|:-----------------:\t|:----------:\t|:----------:\t|:----------:\t|:----------:\t|\n",
    "|  Peter Bonnarens  \t|            \t|            \t|            \t|            \t|\n",
    "| Lennert Franssens \t|     X      \t|     X       \t|     X       \t|     X      \t|\n",
    "|   Philip Kukoba   \t|            \t|            \t|            \t|            \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: imports & loading the dataset\n",
    "In this step we import the needed libraries and read the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "# delete warnings from output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# figure size in inches\n",
    "plt.rcParams['figure.figsize'] = 20,16\n",
    "\n",
    "# loading the dataset into pandas dataframe\n",
    "listings = pd.read_csv(\"data/listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: preprocessing\n",
    "\n",
    "Before we can start our EDA, we need to preprocess our data. This means changing string values to integers, removing NaN values, removing garbage data...\n",
    "Let us first take a look at our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset contains a lot of text values that are not needed for this sprint, and that we start with 923 rows of data and 75 features. The first step is to make a selection of the features we think can be useful or can give us insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A : Feature subset selection\n",
    "\n",
    "Here is a list of the features that we think could possibly be useful during this sprint:\n",
    "* **id**: (int64) unique identifier for the listing\n",
    "* **host_id**: (object) unique identifier for the host\n",
    "* **host_response_time**: (object) description of how long it usually takes the host to respond\n",
    "* **host_response_rate**: (object) the % rate at which the host responds\n",
    "* **host_acceptance_rate**: (object) the % rate at which the host accepts booking requests\n",
    "* **host_total_listings_count**: (int64) The number of listings the host has\n",
    "* **host_verifications**: (object) array containing the different types of verification methods the host supports\n",
    "* **host_has_profile_pic**: (object) boolean value that indicates if the host has a profile picture or not\n",
    "* **host_identity_verified**: (object) boolean value that indicates wether the host is verified or not\n",
    "* **neighbourhood_cleansed**: (object) the neighbourhood as geocoded using the latitude and longitude\n",
    "* **latitude**: (object) latitude of listing\n",
    "* **longitude**: (object) longitude of listing\n",
    "* **room_type**: (object) room type\n",
    "* **accomodates**: (object) maximum capacity of the listing\n",
    "* **bedrooms**: (object) number of bedrooms in the listing\n",
    "* **beds**: (float64) number of beds\n",
    "* **price**: (object) daily price in local currency\n",
    "* **minimum_nights**: (object) minimum number of night stay for the listing\n",
    "* **maximum_nights**: (int64) maximum number of night stay for the listing\n",
    "* **number_of_reviews**: (object) the number of reviews the listing has\n",
    "* **number_of_reviews_ltm**: (int64) the number of reviews the listing has (in the last 12 months)\n",
    "* **last_review**: (object) the date of the last/newest review\n",
    "* **review_scores_rating**: (object) overall rating of the listing\n",
    "* **instant_bookable**: (object) boolean value that indicates wwhether the guest can automatically book the listing without the host requiring to accept their booking request\n",
    "* **reviews_per_month**: (float64) the number of reviews the listing has over the lifetime of the listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that some rows in the dataset contained data that was shifted 1 column to the right starting from the 'host_since' column. Instead of removing these rows from the dataset, we decided to shift these rows 1 column back to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find lines to shift and add them to a mask - we've found that some lines are shifted 1 to the right beginning on the host_id column (that now contains garbage data)\n",
    "shifted_lines = listings[pd.to_numeric(listings[\"host_verifications\"], errors='coerce').notnull()].id\n",
    "mask = listings['id'].isin(shifted_lines)\n",
    "\n",
    "# shift lines 1 to the left\n",
    "listings.loc[mask, 'host_since':'reviews_per_month'] = listings.loc[mask, 'host_since':'reviews_per_month'].shift(-1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these features do not have the types we expect them to be. This is due to the fact that there are still NaN/garbage values in the dataset. Some columns also nead to be cast to the correct type. We can check the types of the columns like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare extra columns to split number of bathrooms per type\n",
    "listings['priv_bath'] = listings['bathrooms_text']\n",
    "listings['bathrooms'] = listings['bathrooms_text']\n",
    "\n",
    "# filter columns\n",
    "\n",
    "listings = listings[[\"id\", \"host_id\", \"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_is_superhost\", \"host_total_listings_count\", \n",
    "    \"host_verifications\", \"host_identity_verified\", \"neighbourhood_cleansed\", \"latitude\", \"longitude\", \"property_type\", \"room_type\",\n",
    "    \"accommodates\", \"priv_bath\", \"bathrooms\", \"bedrooms\", \"beds\", \"price\", \"minimum_nights\", \"maximum_nights\",\"availability_90\",\n",
    "    \"number_of_reviews\", \"number_of_reviews_ltm\", \"last_review\", \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\",\n",
    "    \"review_scores_location\", \"review_scores_value\", \"instant_bookable\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listings.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B : cleaning the data\n",
    "Now all of the data are in the right columns, we can clean the individual records.\n",
    "First we drop the rows where NaN values are present. These rows are considered as corrupt rows that contain invalid or too few data to work with.\n",
    "After dropping these rows, we can convert rows with numeric data saved as strings to numeric types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other rows still contains textual data that can easily be transformed to numeric data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# 0 = best resposne time, 1,2... worse\n",
    "# listings[\"host_response_time\"].unique()\n",
    "\n",
    "#listings[\"host_response_time\"] = [0 if x == 'within an hour' \n",
    "#                                    else 1 if x == 'within a few hours' \n",
    "#                                    else 2 if x == 'within a day' \n",
    "#                                    else 3 if x == 'a few days or more' \n",
    "#                                    else 4\n",
    "#                                    for x in listings[\"host_response_time\"]]\n",
    "\n",
    "# clean property types\n",
    "listings['property_type'] = ['Room'    if re.match('.*room.*', x, re.IGNORECASE) \n",
    "                                            else 'House' if re.match('.*house.*', x, re.IGNORECASE) \n",
    "                                            else 'Apartment' if re.match('.*apartment.*', x, re.IGNORECASE) \n",
    "                                            else 'Other'\n",
    "                                            for x in listings[\"property_type\"]]\n",
    "\n",
    "# convert percentage to float\n",
    "listings[\"host_response_rate\"] = listings['host_response_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "listings['host_acceptance_rate'] = listings['host_acceptance_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "# convert to number of verification types\n",
    "listings['host_verifications'] = listings['host_verifications'].apply(eval).apply(lambda x: len(x))\n",
    "\n",
    "# convert booleans: 1 if true, 0 if false\n",
    "listings[\"host_identity_verified\"] = listings[\"host_identity_verified\"].apply(lambda x: 1 if x == 't' else 0 if x == 'f' else None)\n",
    "listings[\"instant_bookable\"] = listings[\"instant_bookable\"].apply(lambda x: 1 if x == 't' else 0 if x == 'f' else None)\n",
    "listings[\"host_is_superhost\"] = listings[\"host_is_superhost\"].apply(lambda x: 1 if x == 't' else 0 if x == 'f' else None)\n",
    "\n",
    "# private bathroom and shared bathroom\n",
    "listings['bathrooms'] = listings['bathrooms'].replace('\\s.*', '', regex=True)\n",
    "listings['bathrooms'] = listings['bathrooms'].replace('^[a-zA-Z].*', '0.5', regex=True)\n",
    "listings['priv_bath'] = listings['priv_bath'].replace('.*ared.*', '0', regex=True)\n",
    "listings['priv_bath'] = listings['priv_bath'].replace('.*[a-zA-Z].*', '1', regex=True)\n",
    "\n",
    "listings['bathrooms'] = listings['bathrooms'].astype(float)\n",
    "listings['priv_bath'] = listings['priv_bath'].astype(float)\n",
    "\n",
    "# convert currency to float\n",
    "listings['price'] = listings['price'].replace('[\\$,)]', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we drop the rows that contain missing values\n",
    "listings.dropna(inplace=True)\n",
    "\n",
    "# next we convert some columns to numeric values\n",
    "listings[[\"accommodates\", \"bedrooms\", \"minimum_nights\", \"number_of_reviews\", \"review_scores_rating\", \"longitude\", \"beds\", \"host_id\", \"host_total_listings_count\", \"maximum_nights\", \"number_of_reviews_ltm\"]] = listings[[\"accommodates\",\"bedrooms\", \"minimum_nights\", \"number_of_reviews\", \"review_scores_rating\", \"longitude\",\"beds\", \"host_id\", \"host_total_listings_count\", \"maximum_nights\", \"number_of_reviews_ltm\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A: Histograms of most interesting numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.hist(figsize=(25,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B: Distribution and pairplot\n",
    "The first graph shows the distribution of the prices.\n",
    "The second graph shows scatterplots. There we can find out if there are good predictors for our target price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#dataset = listings[[\"price\", \"neighbourhood_cleansed\", \"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_total_listings_count\", \"host_verifications\", \"host_identity_verified\", \"accommodates\", \"bedrooms\", \"beds\", \"minimum_nights\", \"maximum_nights\", \"number_of_reviews\", \"number_of_reviews_ltm\", \"review_scores_rating\", \"instant_bookable\", \"reviews_per_month\", \"room_type\", \"rt_Entire home/apt\", \"rt_Hotel room\", \"rt_Private room\", \"rt_Shared room\"]]\n",
    "dataset = listings[[\"neighbourhood_cleansed\", \"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_is_superhost\", \"host_total_listings_count\", \n",
    "    \"host_verifications\", \"host_identity_verified\", \"property_type\",\"room_type\",\n",
    "    \"accommodates\", \"priv_bath\", \"bathrooms\", \"bedrooms\", \"beds\", \"price\", \"minimum_nights\", \"maximum_nights\", \"availability_90\",\n",
    "    \"number_of_reviews\", \"number_of_reviews_ltm\", \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\",\n",
    "    \"review_scores_location\", \"review_scores_value\", \"instant_bookable\", \"reviews_per_month\"]]\n",
    "sns.distplot(dataset.price, bins=50)\n",
    "plt.xlabel(\"Price\")\n",
    "plt.xticks(np.arange(min(dataset.price.to_numpy()), max(dataset.price.to_numpy()), 50.0))\n",
    "plt.show()\n",
    "\n",
    "#sns.pairplot(dataset, vars=[\"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_total_listings_count\", \"host_verifications\", \"host_identity_verified\", \"accommodates\", \"bedrooms\", \"beds\", \"number_of_reviews\", \"number_of_reviews_ltm\", \"review_scores_rating\", \"instant_bookable\", \"reviews_per_month\", \"room_type\", \"rt_Entire home/apt\", \"rt_Hotel room\", \"rt_Private room\", \"rt_Shared room\"])\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "for i, k in enumerate(dataset.keys()):\n",
    "    plt.subplot(7,7,1+i)\n",
    "    plt.xticks(rotation=90)\n",
    "    sns.scatterplot(x=dataset[k], y=dataset[\"price\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C: Boxplots\n",
    "Some boxplots to gain more insight about the used price range per accommodate, room type and neighbourhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.boxplot(x=\"accommodates\", y=\"price\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "sns.boxplot(x=dataset.room_type, y=dataset.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(x=dataset.neighbourhood_cleansed, y=dataset.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D: Impact on the price if host has more than one listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3E: Correlation between review score and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3F: Correlation between review score and number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3G: Number of listings per number of accommodates, bathrooms, bedrooms and beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['accommodates', 'bathrooms', 'bedrooms', 'beds']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3H: Distribution of property and room type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['room_type'].hist()\n",
    "dataset['room_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['property_type'].hist()\n",
    "dataset['property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3H: One-hot encodings and correlation matrix\n",
    "We do a one-hot encoding for categorical features. After that we can plot a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical features with one-hot encodings\n",
    "a = pd.get_dummies(listings['host_response_time'], prefix = \"hrt\")\n",
    "b = pd.get_dummies(listings['room_type'], prefix = \"rt\")\n",
    "c = pd.get_dummies(listings['property_type'], prefix = \"pt\")\n",
    "frames = [listings, a, b, c]\n",
    "listings = pd.concat(frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = listings.corr().round(2)\n",
    "plt.figure(figsize=(20,14))\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3I: Log transformation of columns that could benefit from it\n",
    "We can see that there are some features that could benefit from a log transformation. This can be concluded from the histograms from 3A.\n",
    "\n",
    "After the transformation we can see that there are some features that are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfo_listings = listings[[\"host_total_listings_count\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"price\", \"minimum_nights\", \"maximum_nights\", \"number_of_reviews\"]]\n",
    "\n",
    "for col in tfo_listings.keys():\n",
    "    tfo_listings[col] = tfo_listings[col].astype('float64').replace(0.0, 0.01)\n",
    "    tfo_listings[col] = np.log(tfo_listings[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfo_listings.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop some colums that are not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['neighbourhood_cleansed'], inplace=True, axis=1)\n",
    "dataset.drop(['room_type'], inplace=True, axis=1)\n",
    "dataset.drop(['property_type'], inplace=True, axis=1)\n",
    "dataset.drop(['host_response_time'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Train - Test - Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfo_listings.drop(['price'], axis=1) # pd.concat((), axis=1)\n",
    "y = tfo_listings['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# formule: x-xmin/xmax-xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()\n",
    "lin_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_predict = lin_model.predict(x_train)\n",
    "y_test_predict = lin_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Measure the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "n_train = len(x_train)  # sample size\n",
    "p_train = len(x_train.columns)  # number of independent variables\n",
    "R2_train = r2_score(y_train, y_train_predict)\n",
    "RMSE_train = (np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "# use the adjusted RÂ² score to counter accidental increase of score with number of input features.\n",
    "adj_R2_train = 1 - ((1-R2_train) * (n_train-1)/(n_train-p_train-1))   #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "\n",
    "print(\"Model train performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(RMSE_train))\n",
    "print('R2 score is {}'.format(R2_train))\n",
    "print('adjusted R2 score is {}'.format(adj_R2_train))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "n_test = len(x_test)\n",
    "p_test = len(x_test.columns)\n",
    "R2_test = r2_score(y_test, y_test_predict)\n",
    "RMSE_test = (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "adj_R2_test = 1 - ((1-R2_test) * (n_test-1)/(n_test-p_test-1))   #Adj R2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "\n",
    "print(\"Model test performance\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(RMSE_test))\n",
    "print('R2 score is {}'.format(R2_test))\n",
    "print('adjusted R2 score is {}'.format(adj_R2_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Model parameters\")\n",
    "print(\"--------------------------------------\")\n",
    "print(lin_model.coef_)\n",
    "print(lin_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predicted values with the actual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_array = np.array(list(y_test))\n",
    "y_test_predict_array = np.array(y_test_predict)\n",
    "compare_table = pd.DataFrame({'Truth': y_test_array.flatten(), 'Predicted': y_test_predict_array.flatten()})\n",
    "compare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def run_predictions(tree, x):\n",
    "    predictions = []\n",
    "    for index, sample in x.iterrows():\n",
    "        prediction = tree.predict(sample)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "    \n",
    "def visualize_results(predictions, ground_truth):\n",
    "    \n",
    "    plt.scatter(ground_truth, predictions, alpha=0.5)\n",
    "    plt.xlabel(\"Ground truth price\")\n",
    "    plt.ylabel(\"Predicted price\")\n",
    "    plt.show()\n",
    "    \n",
    "    rmse = (np.sqrt(mean_squared_error(ground_truth, predictions)))\n",
    "    r2 = r2_score(ground_truth, predictions)\n",
    "    print('RMSE is {}'.format(rmse))\n",
    "    print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset in training and test set \n",
    "#TODO choose features more wisely\n",
    "\n",
    "ds_copy = tfo_listings #dataset[[\"price\", \"host_response_time\", \"host_total_listings_count\", \"host_verifications\", \"host_identity_verified\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"minimum_nights\", \"maximum_nights\", \"instant_bookable\"]]\n",
    "X = ds_copy.drop(['price'], axis=1)\n",
    "Y = ds_copy[\"price\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=8, random_state=0)\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "predictions = regr.predict(X_test)\n",
    "\n",
    "visualize_results(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the RMSE and R2 measurements that the random forest regression does not deliver the best result. But we see the right shape of y=x with some noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Use one-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done in first part of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Normalizing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dataset = tfo_listings #dataset[[\"price\", \"host_response_time\", \"host_total_listings_count\", \"host_verifications\", \"host_identity_verified\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"minimum_nights\", \"maximum_nights\", \"instant_bookable\"]]\n",
    "#columns = [\"host_total_listings_count\", \"host_verifications\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\"]\n",
    "#knn_dataset[columns] = (knn_dataset[columns] - np.min(knn_dataset[columns])) / (np.max(knn_dataset[columns]) - np.min(knn_dataset[columns])).values\n",
    "#knn_dataset.describe()\n",
    "#knn_dataset.dtypes\n",
    "\n",
    "# Split data in a training and test set\n",
    "y = knn_dataset.price.values\n",
    "x = knn_dataset.drop(['price'], axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm\n",
    "class MyKNeighborsClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    def fit(self, x, y):\n",
    "        self.tree = KDTree(x)\n",
    "        self.y = y\n",
    "    def predict(self, x):\n",
    "        _, ind = self.tree.query(x, k=self.k)\n",
    "        return self.y[ind].mean(axis=1)\n",
    "\n",
    "\n",
    "knn = MyKNeighborsClassifier(3)\n",
    "knn.fit(x_train, y_train)\n",
    "predictions = knn.predict(x_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Measure the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix these tests!!! Use the y_test to compare to the predictions values.\n",
    "#accuracy = (predictions == y_test).mean()\n",
    "\n",
    "# TODO: Remove outliers (less common listings) - where price > 170\n",
    "accuracy = np.where((predictions > y_test - 20) & (predictions < y_test + 20), True, False).mean()\n",
    "print(accuracy)\n",
    "\n",
    "#TP = (predictions[y_test == 1] == 1).sum()\n",
    "#print(TP)\n",
    "\n",
    "#TN = (predictions[y_test == 0] == 0).sum()\n",
    "#print(TN)\n",
    "\n",
    "#FP = (predictions[y_test == 1] == 0).sum()\n",
    "#print(FP)\n",
    "\n",
    "#FN = (predictions[y_test == 0] == 1).sum()\n",
    "#print(FN)\n",
    "\n",
    "#accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "#print(accuracy)\n",
    "\n",
    "#precision = TP / (TP + FP)\n",
    "#print(precision)\n",
    "\n",
    "#recall = TP / (TP + FN)\n",
    "#print(recall)\n",
    "\n",
    "#F1 = 2 *  (precision*recall)/(precision+recall)\n",
    "#print(F1)\n",
    "\n",
    "#accuracies = []\n",
    "#for k in range(1, 50):\n",
    "#    knn = MyKNeighborsClassifier(k)\n",
    "#    knn.fit(x_train, y_train)\n",
    "#    predictions = knn.predict(x_test)  > 0.5\n",
    "#    accuracies.append((predictions == y_test).mean())\n",
    "#plt.plot(accuracies)\n",
    "\n",
    "\n",
    "#knn = MyKNeighborsClassifier(5)\n",
    "#knn.fit(x_train, y_train)\n",
    "#predictions = knn.predict(x_test)\n",
    "\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "#roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "#plt.plot(fpr, tpr, color='darkorange', label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "#plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "\n",
    "#for x, y, txt in zip(fpr, tpr, thresholds):\n",
    "#    plt.annotate(np.round(txt,2), (x, y-0.04))\n",
    "    \n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver operating characteristic')\n",
    "#plt.legend(loc=\"lower right\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64c1ee026d8bf8fe0f80fca881c6aaba787117ac29ac9f2de19bb4b209b90df9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
