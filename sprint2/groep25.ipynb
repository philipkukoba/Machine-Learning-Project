{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machinaal Leren - Sprint 2: Text Data\n",
    "\n",
    "## Task:\n",
    "What insights can we gain from the text data (title, description and reviews) ?\n",
    "\n",
    "Possible tasks:\n",
    "* Detect duplicate listings\n",
    "* Extract keywords from reviews / descriptions\n",
    "* Automatically make a list of positive and negative points for a listing based on the reviews\n",
    "* Recognize listings from the same owner\n",
    "* Detect anomalies (listings/ reviews that are very different from other listings/ reviews)\n",
    "* Detect reviews that are very similar\n",
    "* Perform sentiment analysis on a review\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Task|Peter Bonnarens|Philip Kukoba|Lennert Franssens|\n",
    "|------|------|------|------|\n",
    "|Detect duplicate listings  |X  |X  | X |\n",
    "|Extract keywords  |_  |_  | _ |\n",
    "|Automatically make a list  |_  |_  | _ |\n",
    "|Recognize listings from the same owner  |_  |_  | _ |\n",
    "|Detect anomalies  |_  |_  | _ |\n",
    "|Detect reviews that are very similar  |_  |_  | _ |\n",
    "|Perform sentiment analysis on a review  |_  |_  | _ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "from matplotlib import rcParams\n",
    "import warnings\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# delete warnings from output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# figure size in inches\n",
    "plt.rcParams['figure.figsize'] = 15, 12\n",
    "\n",
    "# loading the datasets into pandas dataframes\n",
    "reviews = pd.read_csv(\"data/reviews.csv\")\n",
    "listings = pd.read_csv(\"data/listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find lines to shift and add them to a mask - we've found that some lines are shifted 1 to the right beginning on the host_id column (that now contains garbage data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_lines = listings[pd.to_numeric(listings[\"host_verifications\"], errors='coerce').notnull()].id\n",
    "mask = listings['id'].isin(shifted_lines)\n",
    "\n",
    "# shift lines 1 to the left\n",
    "listings.loc[mask, 'host_since':'reviews_per_month'] = listings.loc[mask, 'host_since':'reviews_per_month'].shift(-1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop(['host_response_time','host_response_rate','host_acceptance_rate','host_is_superhost','host_listings_count','host_total_listings_count',\n",
    "            'host_has_profile_pic','host_identity_verified','latitude','longitude','accommodates','bathrooms','bedrooms','beds','price','minimum_nights',\n",
    "            'maximum_nights','minimum_minimum_nights','maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "            'maximum_nights_avg_ntm','calendar_updated','has_availability','availability_30','availability_60','availability_90','availability_365',\n",
    "            'number_of_reviews','number_of_reviews_ltm','number_of_reviews_l30d','first_review','last_review','license','instant_bookable','calculated_host_listings_count',\n",
    "            'calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms',\n",
    "            'reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows without comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna()\n",
    "reviews_points = reviews.copy()\n",
    "\n",
    "# Remove <b> tags and text in between it\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'<b>.*?<\\/b>', '', regex=True)\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'<b>.*?<\\/b>', '', regex=True)\n",
    "\n",
    "# Remove all HTML tags\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'<[^<>]*>', ' ', regex=True)\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'<[^<>]*>', ' ', regex=True)\n",
    "\n",
    "# Remove all special characters (non-word)\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'\\W', ' ', regex=True)\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'[^\\w\\s\\'\\.\\/]', '.', regex=True)\n",
    "\n",
    "# Remove all single characters (like a floating 'b' after removing the HTML tags around it)\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ', regex=True)\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ', regex=True)\n",
    "\n",
    "# Remove single characters at the start\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'\\^[a-zA-Z]\\s+', ' ', regex=True)\n",
    "#reviews_points['comments'] = reviews_points['comments'].str.replace(r'\\^[a-zA-Z]\\s+', ' ', regex=True)\n",
    "\n",
    "# Substitute multiple spaces with a single space\n",
    "reviews['comments'] = reviews['comments'].str.replace(r'\\s+', ' ', regex=True)\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Replace multiple dots with one dot\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'\\.+', '.', regex=True)\n",
    "\n",
    "# Remove space(s) before dot\n",
    "reviews_points['comments'] = reviews_points['comments'].str.replace(r'\\s+\\.', '.', regex=True)\n",
    "\n",
    "# Convert to lowercase\n",
    "reviews['comments'] = reviews['comments'].str.lower()\n",
    "reviews_points['comments'] = reviews_points['comments'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove <b> tags and text in between it\n",
    "listings['description'] = listings['description'].str.replace(r'<b>.*?<\\/b>', '', regex=True)\n",
    "\n",
    "# Remove all HTML tags\n",
    "listings['description'] = listings['description'].str.replace(r'<[^<>]*>', ' ', regex=True)\n",
    "listings = listings[listings['description'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect duplicate listings\n",
    "To detect duplicates we compare entries based on the description column. The column should be carefully chosen since e.g. comparing based on the name might mark non-duplicates as duplicates, if both have the same generic name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listings[listings.duplicated(['description']) == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive and negative points from a listing review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in your environment: python -m pip install textblob\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_points['comments'] = reviews_points['comments'].apply(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in reviews_points.iterrows():\n",
    "    comment = row.comments\n",
    "    positive = []\n",
    "    negative = []\n",
    "    for sentence in comment.sentences:\n",
    "        if sentence.sentiment.polarity < -0.3:\n",
    "            negative.append(str(sentence).replace('.', ''))\n",
    "        elif sentence.sentiment.polarity > 0.3:\n",
    "            positive.append(str(sentence).replace('.', ''))\n",
    "    print(\"\\n----- COMMENT -----\")\n",
    "    print(\"listing_id: \", row.listing_id)\n",
    "    print(\"comment: \", comment)\n",
    "    print(\"positive points: \", positive)\n",
    "    print(\"negative points: \", negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract keywords from reviews using TF-IDF\n",
    "\n",
    "TODO WRITE INTRO\n",
    "\n",
    "TODO EXTEND FOR DESCRIPTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running TF-IDF, we first have to detect the language of each review (since for example stop words are unique for a language). Be warned, the code below takes a while to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this in your environment: python -m pip install langdetect\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "all_languages = []\n",
    "for review in reviews[\"comments\"].values:\n",
    "    try:\n",
    "        all_languages.append(detect(review))\n",
    "    except: #the detect func rarely fails, but when it does it can crash the for loop\n",
    "        all_languages.append(\"unknown\")\n",
    "# all_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a column to our dataframe and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"language\"] = all_languages\n",
    "reviews[\"language\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most reviews are in English (en). We will keep only the English reviews since most libraries are optimal for English (eg stop words for tf-idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_reviews = reviews[reviews[\"language\"] == 'en']\n",
    "english_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set-up the CountVectorizer and TfidTransformer properly for TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,    # todo experiment with different values\n",
    "    max_df=0.5\n",
    ")\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(english_reviews[\"comments\"])\n",
    "\n",
    "tf_transformer = TfidfTransformer()\n",
    "X_train_tf = tf_transformer.fit_transform(X_train_counts) # is a matrix\n",
    "\n",
    "X_train_tf   # matrix of #entries x #words(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a column to our DataFrame with the top 5 keywords for this comment based on TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=count_vect.get_feature_names()\n",
    "\n",
    "\n",
    "#todo fix this... at the end it uses a too large index for some reason\n",
    "\n",
    "top_5_keywords_column = []\n",
    "i = 0 \n",
    "for review in reviews[\"comments\"]: \n",
    "    print(i)\n",
    "    np_arr = np.array(X_train_tf[i])\n",
    "    top_5_tf_idf_indices = np.array(X_train_tf[i]).argsort()[:5]\n",
    "    #print(\"got here\")\n",
    "    \n",
    "    top_5_keywords = []\n",
    "    for ind in top_5_tf_idf_indices:\n",
    "        top_5_keywords.append(feature_names[ind])\n",
    "    \n",
    "    top_5_keywords_column.append(top_5_keywords)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "reviews_english[\"top_5_keywords\"] = top_5_keywords_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64c1ee026d8bf8fe0f80fca881c6aaba787117ac29ac9f2de19bb4b209b90df9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
